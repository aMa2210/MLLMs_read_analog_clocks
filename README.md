This repository contains data for analyzing the ability of Multimodal Large Language Models (MLLMs) to read analog clocks.

Repository Contents
- GPT-4o: Contains the results for gpt-4o-2024-08-06, demonstrating that, starting from a near-zero ability to read clocks, MLLMs can successfully learn to interpret them after fine-tuning on the task.
- GPT-4.1: Contains the results for gpt-4.1-2025-04-14, showcasing how a model, already familiar with certain patterns, performs differently when interpreting various types of analog clocks.

The promot used in the experiment is _What time is shown on the clock in the given image?_
